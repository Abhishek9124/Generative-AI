{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNL7Da8SPWuo1cz0l4j3wD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek9124/Generative-AI/blob/main/Video_and_Audio_understanding_capability_of_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xNs_CQ82fwU",
        "outputId": "08f48320-e651-40da-ea7c-def0300ed299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.genai.client.Client at 0x7d3810669d90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "client = genai.Client(api_key=\"\")\n",
        "client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install google-genai"
      ],
      "metadata": {
        "id": "ULGDAG_a2zii"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini models can work with videos, making it possible to do things that used to need special, separate models. With Gemini's vision abilities, you can:\n",
        "# Describe what's happening in a video\n",
        "# Summarize and form notes out of video.\n",
        "# ‚Ä¢ Split videos into parts and pull out key information\n",
        "# ‚Ä¢ Answer questions about what's in the video\n",
        "# ‚Ä¢ Point to exact moments in the video\n",
        "# This is all possible because Gemini was built to be multimodal from the ground up"
      ],
      "metadata": {
        "id": "zL2CHu-923rf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini's Approach (Built-in): Gemini was designed and trained from the ground up on different types of data (text, images, audio, video) all mixed together. It\n",
        "# doesn't have a separate \"brain\" for each sense. It has one unified model that learned the and sounds\n",
        "# simultaneously. This allows for a much deeper and more nuanced understanding."
      ],
      "metadata": {
        "id": "jnxgGDEF3Azl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Older Systems (Stitched Together): Previous Al systems would have separate models: one for understanding images, one for transcribing audio, and one for\n",
        "# processing text. They would analyze a video, pass the separate results to a language model, and try to \"stitch\" the understanding together. This is inefficient and\n",
        "# loses a lot of crucial context (like the exact timing of a sound with a visual action).\n",
        "# Gemini's Approach (Built-in): Gemini was designed and trained from the ground up on different types of data (text, images, audio, video) all mixed together. It\n",
        "# doesn't have a separate \"brain\" for each sense. It has one unified model that learned the and sounds\n",
        "# simultaneously. This allows for a much deeper and more nuanced understanding."
      ],
      "metadata": {
        "id": "Bljnci7KR1wH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### üåü **Gemini ‚Äì What Makes It Special for Video**\n",
        "# #### üé• 1. **Native Multimodality**\n",
        "# * Understands **sound + visuals together**\n",
        "# * Syncs timing perfectly\n",
        "# * Example insight:\n",
        "#   > ‚ÄúThe strange engine noise started exactly when the warning light flashed on the dashboard.‚Äù\n",
        "# #### üß† 2. **Long Context Window**\n",
        "# * **Huge memory capacity** ‚Äî up to **1 million tokens** (10 million in research)\n",
        "# * Can remember an **entire long video** (like a movie or lecture)\n",
        "# * Answers questions about the **beginning using context from the end**\n",
        "# * **No forgetting** of earlier scenes or frames\n",
        "# #### üìπ 3. **High-Quality Video Input**\n",
        "# * Processes videos in **high resolution**\n",
        "# * Handles **fast frame rates**\n",
        "# * Can detect:\n",
        "#   * **Tiny hand movements**\n",
        "#   * **Small on-screen text**\n",
        "#   * **Fast-moving objects**"
      ],
      "metadata": {
        "id": "BCJ6qmhqR57U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIDEO UNDERSTANDING CAPABILITY OF GEMINI"
      ],
      "metadata": {
        "id": "1cDtjSSuSxOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "video_file_name=\"/content/GORILLA.mp4\"\n",
        "video_bytes=open(video_file_name,\"rb\").read()\n",
        "response=client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=types.Content(\n",
        "        parts=[types.Part(\n",
        "            inline_data=types.Blob(data=video_bytes,mime_type=\"video/mp4\")\n",
        "        ),\n",
        "               types.Part(\n",
        "                   text=\"Please summarize the video in 3 sentences\"\n",
        "               )]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "WNPIo4oISjlX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)   #only works when request size is less then 20MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXCuhuohU3r3",
        "outputId": "39c00164-b7c4-406a-ef04-5e65d49ec2dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A gorilla stands on the grassy bank of a tranquil river in a lush, forested environment. It briefly beats its chest before waving and greeting the viewer with \"Hello there, friends!\" and commenting on the beautiful day. The gorilla then turns its head to look across the water, where several indistinct figures are visible on the opposite bank.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we use file api to upload the data"
      ],
      "metadata": {
        "id": "MMqpsRNMVR65"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myfile=client.files.upload(file=\"/content/GORILLA.mp4\")\n",
        "prompt=\"Summarize this video\"\n"
      ],
      "metadata": {
        "id": "8bej3PKNXoZ_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myfile=client.files.get(name=myfile.name).state.name\n",
        "print(myfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdI3WjVgaO4Y",
        "outputId": "bf4fcc68-7cdf-4f70-e21f-08096b143af8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACTIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=client.models.generate_content(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    contents=[myfile,prompt]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeRhNahHJfon",
        "outputId": "2f5e480f-1899-4305-8623-e4c22e42e736"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course. Here is a summary of the video \"Why You Should Start a 'Dopamine Detox'\" by Andrew Kirby.\n",
            "\n",
            "### Summary of \"Why You Should Start a 'Dopamine Detox'\"\n",
            "\n",
            "This video explains the concept of a \"dopamine detox\" as a practical method to reset your brain's reward system, combat procrastination, and regain motivation for difficult but important tasks. The central idea is that our modern environment overloads us with easy, high-dopamine activities (like social media, video games, junk food, and internet browsing), which makes us less sensitive to the pleasure derived from normal, productive activities.\n",
            "\n",
            "**Key Concepts Explained:**\n",
            "\n",
            "*   **The Problem:** Constant engagement in high-dopamine activities creates a cycle of seeking instant gratification. This lowers your baseline level of dopamine, meaning you need more and more stimulation to feel pleasure or motivation. As a result, difficult, low-dopamine activities (like studying, exercising, or working on a long-term project) feel boring and unrewarding.\n",
            "*   **The Solution (Dopamine Detox):** A dopamine detox is a period of intentionally abstaining from these high-dopamine, low-effort activities. By starving your brain of this cheap stimulation, you allow your dopamine receptors to \"reset.\" This makes naturally rewarding, low-dopamine activities feel more engaging and pleasurable again. The video compares it to how plain food tastes much better when you haven't eaten sugary junk food for a while.\n",
            "*   **The Goal:** The ultimate goal is not to eliminate all pleasure, but to regain control over your focus and motivation. By resetting your baseline, you can find satisfaction and drive in the work that truly matters to you.\n",
            "\n",
            "**How to Implement a Dopamine Detox (Levels of Intensity):**\n",
            "\n",
            "The video proposes a tiered approach, allowing you to choose a level that suits your lifestyle:\n",
            "\n",
            "1.  **Beginner (The Monk Morning):** For the first 1-2 hours of your day, do not engage with any high-dopamine distractions. This means no phone, no social media, and no entertainment. Instead, focus on productive or healthy habits like meditation, journaling, reading a physical book, or working on your most important task.\n",
            "2.  **Intermediate (The Dopamine Fasting Day):** Dedicate one full day a week (e.g., Sunday) to a complete detox. On this day, you abstain from all major sources of cheap dopamine, such as the internet, music, junk food, and social interaction, focusing instead on activities like walking, meditating, reading, and planning.\n",
            "3.  **Advanced (Monk Mode):** This involves a longer, more immersive period of detoxification, such as a full week or even a month. This is a significant commitment designed for a major mental reset, forcing you to confront boredom and find fulfillment in focused, meaningful work.\n",
            "\n",
            "In essence, the video argues that by strategically managing your dopamine intake, you can rewire your brain to stop craving distraction and start enjoying the process of achieving your goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    contents=types.Content(\n",
        "        parts=[types.Part(\n",
        "            file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "        ),\n",
        "               types.Part(\n",
        "                   text=\"Price of the course fee\"\n",
        "               )]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "WDx8gfzXaVKr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "id": "nl0hjKU8cxMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3857148f-f7db-40a4-8dad-17647a634807"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The course fee is Rs 7,999/-.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate summary\n",
        "# QA about video"
      ],
      "metadata": {
        "id": "qFvwhAdkc6nG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MP4 to MP3"
      ],
      "metadata": {
        "id": "i6CTOuA_ejjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response=client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=types.Content(\n",
        "        parts=[types.Part(\n",
        "            file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "        ),\n",
        "               types.Part(\n",
        "                   text=\"Transcribe complete video \"\n",
        "               )]\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "qLkIeeWteZw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8d9ecb-e8f0-4bd4-8313-d3f7a3498c4d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The video features Nitish Singh introducing a new data analytics mentorship program (DAMP) by CampusX. The online mentorship is for six to eight months, helping students understand data analytics from end-to-end to help them get a job as a data analyst or business analyst. Nitish says the data analyst profile has the largest number of openings and is the most accessible to those who want to get started.\n",
            "\n",
            "The reasons CampusX has started the course is because they recognize the demand for these positions, as well as the gaps in the market. They have noticed that not all courses are providing all the skills needed to be an analyst. So, CampusX decided to create a program with those skills, and give students the tools, technologies, and concepts to be successful. \n",
            "\n",
            "One of the program features is that it is a live, interactive course of 100+ hours of instruction through two-hour long live lectures. There is also a curriculum designed around what employers are looking for in the industry. Each lecture is recorded and made available for viewing within a period of three years. \n",
            "\n",
            "As to who will benefit most from the program, Nitish says it is anyone who wants to be a data analyst or data scientist and who likes to learn using the CampusX method.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMOTION AND SENTIMENT DETECTION"
      ],
      "metadata": {
        "id": "2DlzcL5UgqAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# response=client.models.generate_content(\n",
        "#     model=\"gemini-2.0-flash-exp\",\n",
        "#     contents=types.Content(\n",
        "#         parts=[types.Part(\n",
        "#             file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "#         ),\n",
        "#                types.Part(\n",
        "#                    text=\"Analyze the video and describe the emotion of moves in each scenes based on tone of voice and facial expressions\"\n",
        "#                )]\n",
        "#     )\n",
        "# )\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "ANsg5Gy3eitF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response=client.models.generate_content(\n",
        "#     model=\"gemini-2.0-flash-exp\",\n",
        "#     contents=types.Content(\n",
        "#         parts=[types.Part(\n",
        "#             file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "#         ),\n",
        "#                types.Part(\n",
        "#                    text=\"Extract all the on screen text along with is timestamp\"\n",
        "#                )]\n",
        "#     )\n",
        "# )\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "X2KfzvaMhLSv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPARE MULTIPLE VIDEOS"
      ],
      "metadata": {
        "id": "GifOWF04hvuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# response=client.models.generate_content(\n",
        "#     model=\"gemini-2.0-flash-exp\",\n",
        "#     contents=types.Content(\n",
        "#         parts=[types.Part(\n",
        "#             file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "#         ),\n",
        "#                types.Part(\n",
        "#             file_data=types.FileData(file_uri=\"https://youtu.be/yBsJQltbH9E?si=xkTyijwyASsIOSY2\")\n",
        "#         ),\n",
        "#                types.Part(\n",
        "#                    text=\"Extract all the on screen text along with is timestamp\"\n",
        "#                )]\n",
        "#     )\n",
        "# )\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "cvG95F8shlam"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUDIO UNDERSTANDING"
      ],
      "metadata": {
        "id": "LrZTe8oZjLaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Video understanding vision + audio combined.\n",
        "# Audio understanding = focuses purely on sound (speech, music, noises) without isuals.\n",
        "# Gemini can analyze and understand audio input, enabling use cases like the fol owing:\n",
        "# Describe, sumarize, or answer questions about audio content.\n",
        "# provide a transcription of the audio.\n",
        "# Anayze specific segments of the audio."
      ],
      "metadata": {
        "id": "Nh_hCx3XjNBC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# myfile=client.files.upload(file=\"mp3\")\n",
        "# prompt=\"Describe the audio clip\"\n",
        "# response=client.models.generate_content(\n",
        "#     model=\"gemini-2.0-flash-exp\",\n",
        "#     contents=[myfile,prompt]\n",
        "# )\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "LzSfXqehjgD4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# refer notes"
      ],
      "metadata": {
        "id": "1fno26D2lXmP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TvfWB-5Ht39"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}